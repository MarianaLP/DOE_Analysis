{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOE Reference Building Analysis for Climate Region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set climate region to match weatherfile\n",
    "climate_region = '5a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EnergyPlus version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_version = '9.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and configure workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mariana\\desktop\\projects\\buildingtechnology\\containerfarmep\\archetypal_files\\archetypal\\archetypal\\utils.py:117: UserWarning: The TRNSYS path does not exist. Please set the TRNSYS path with the --trnsys-default-folder option\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import archetypal as ar\n",
    "import pandas as pd\n",
    "import os\n",
    "from path import Path\n",
    "\n",
    "# to disable, %matplotlib inline\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "ar.config(use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "This workbook uses a branched version of archetypal to be able to index idf.meters.OutputMeter[ ] objects. \n",
    "\n",
    "This workbook should be run in a directory that containes a subdirectory named according to the climate region (e.g., \"5a\"). Within the climate region directory, there need to be the following directories:\n",
    "    \n",
    "    IDF: contains all the DOE reference building IDF files for the climate region\n",
    "    UMI: if applicable, contains any UMI results in the format of annual hourly results\n",
    "    WeatherFile: contains the weather file for the climate region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "\n",
    "Lists of all reference buildings and Epochs to match the string names used in the IDF files. Additionally, the headers that will be used in the results dataframes match the hourly results categories outpud from UMI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# ---------------- GLOBAL VARIABLES ------------------------\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "all_buildings = ['LargeOffice',\n",
    "                 'MediumOffice',\n",
    "                 'SmallOffice',\n",
    "                 'Warehouse',\n",
    "                 'Stand-aloneRetail',\n",
    "                 'StripMall',\n",
    "                 'PrimarySchool',\n",
    "                 'SecondarySchool',\n",
    "                 'Supermarket',\n",
    "                 'QuickServiceRestaurant',\n",
    "                 'FullServiceRestaurant',\n",
    "                 'Hospital',\n",
    "                 'OutPatient',\n",
    "                 'SmallHotel',\n",
    "                 'LargeHotel',\n",
    "                 'MidriseApartment']\n",
    "all_epochs = [\"Pre1980\", \"Post1980\", \"New2004\"]\n",
    "\n",
    "energy_header = ['Cooling (kWh/m2)',\n",
    "                  'Heating (kWh/m2)',\n",
    "                  'Lights (kWh/m2)',\n",
    "                  'Equipment (kWh/m2)',\n",
    "                  'DHW (kWh/m2)',\n",
    "                  'EUI (kWh/m2)']\n",
    "sim_header = ['EP','UMI','error']\n",
    "\n",
    "date_index = pd.date_range(start='2018/01/01', end='2019/1/1', closed='left', freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Generate Results Dataframe for a given DOE IDF File\n",
    "\n",
    "This function takes in an IDF file and calculates the normalized energy consumed for cooling, heating, lighting, equipment, and hot water end uses. Additionally, this function calculates a total EUI in kWh/m2 as the sum of these five energy use categories. \n",
    "\n",
    "The function returns a dataframe with these values for 8760 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResultsDF(idf):\n",
    "    #conditioned floor area used to normalize EUI results\n",
    "    area = idf.net_conditioned_building_area #m2\n",
    "    \n",
    "    #local dateindex values\n",
    "    date_index_local = pd.date_range(start='2018/01/01', end='2019/1/1', closed='left', freq='H')\n",
    "    \n",
    "    #create a blank dataframe to store results\n",
    "    results = pd.DataFrame(index=date_index_local)\n",
    "\n",
    "    # cooling end uses\n",
    "    cooling_energy = (\n",
    "        \"CoolingCoils__EnergyTransfer\"\n",
    "    )\n",
    "    # heating end uses\n",
    "    heating_energy = (\n",
    "        \"HeatingCoils__EnergyTransfer\",\n",
    "        \"Baseboard__EnergyTransfer\"\n",
    "    )\n",
    "    \n",
    "    # get total cooling and total heating energy\n",
    "    total_cooling_energy = pd.Series(0,index=date_index_local)\n",
    "    for item in cooling_energy:\n",
    "        try:\n",
    "            total_cooling_energy += (idf.meters.OutputMeter[item].values(\"kWh\"))\n",
    "        except KeyError:\n",
    "            pass  # pass if meter does not exist for model\n",
    "    \n",
    "    total_heating_energy = pd.Series(0,index=date_index_local)\n",
    "    for item in heating_energy:\n",
    "        try:\n",
    "            total_heating_energy += (idf.meters.OutputMeter[item].values(\"kWh\"))\n",
    "        except KeyError:\n",
    "            pass  # pass if meter does not exist for model\n",
    "    \n",
    "    # calculate ratio of cooling and heating energy for use in cooling and heating fan and pump energy\n",
    "    ratio_cooling = total_cooling_energy / (total_cooling_energy+total_heating_energy)\n",
    "    ratio_heating = total_heating_energy / (total_cooling_energy+total_heating_energy)\n",
    "\n",
    "      \n",
    "    #calcualte fans electricity for cooling and heating\n",
    "\n",
    "    if 'Fans__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        fans_cooling = idf.meters.OutputMeter.Fans__Electricity.values('kWh') * ratio_cooling /area\n",
    "        fans_heating = idf.meters.OutputMeter.Fans__Electricity.values('kWh') * ratio_heating /area       \n",
    "    else:\n",
    "        fans_cooling = pd.Series(0,index=date_index_local)\n",
    "        fans_heating = pd.Series(0,index=date_index_local)\n",
    "    \n",
    "   \n",
    "    #calculate pumps electricity for cooling and heating\n",
    "    \n",
    "    if 'Pumps__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        pumps_cooling = idf.meters.OutputMeter.Pumps__Electricity.values('kWh') * ratio_cooling /area\n",
    "        pumps_heating = idf.meters.OutputMeter.Pumps__Electricity.values('kWh') * ratio_heating /area\n",
    "    else:\n",
    "        pumps_cooling = pd.Series(0,index=date_index_local)\n",
    "        pumps_heating = pd.Series(0,index=date_index_local)\n",
    "    \n",
    "    #cooling\n",
    "    if 'Cooling__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] = idf.meters.OutputMeter.Cooling__Electricity.values(units = ('kWh'))/area\n",
    "    else:\n",
    "        results['Cooling (kWh/m2)'] = pd.Series(0,index=date_index_local)\n",
    "        \n",
    "    if 'HeatRejection__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += idf.meters.OutputMeter.HeatRejection__Electricity.values(units = ('kWh'))/area\n",
    "\n",
    "    if 'Cooling__Gas' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += idf.meters.OutputMeter.Cooling__Gas.values(units = ('kWh'))/area\n",
    "  \n",
    "    if 'Cooling__DistrictCooling' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += idf.meters.OutputMeter.Cooling__DistrictCooling.values(units = ('kWh'))/area\n",
    "\n",
    "    if 'Fans__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += fans_cooling\n",
    "        \n",
    "    if 'Pumps__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += pumps_cooling\n",
    "\n",
    "    \n",
    "    #heating\n",
    "    if 'Heating__Gas' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Heating (kWh/m2)'] = idf.meters.OutputMeter.Heating__Gas.values(units = ('kWh'))/area \n",
    "    else:\n",
    "        results['Heating (kWh/m2)'] = pd.Series(0,index=date_index_local)\n",
    "        \n",
    "    if 'Heating__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Heating (kWh/m2)'] += idf.meters.OutputMeter.Heating__Electricity.values(units = ('kWh'))/area\n",
    "        \n",
    "    if 'Heating__DistrictHeating' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Heating (kWh/m2)'] += idf.meters.OutputMeter.Heating__DistrictHeating.values(units = ('kWh'))/area\n",
    "        \n",
    "    if 'Heating__Oil' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Heating (kWh/m2)'] += idf.meters.OutputMeter.Heating__Oil.values(units = ('kWh'))/area \n",
    "        \n",
    "    if 'Fans__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += fans_heating\n",
    "        \n",
    "    if 'Pumps__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Cooling (kWh/m2)'] += pumps_heating\n",
    "\n",
    "    \n",
    "    #lights\n",
    "    if 'InteriorLights__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Lights (kWh/m2)'] = idf.meters.OutputMeter.InteriorLights__Electricity.values(units = ('kWh'))/area\n",
    "    else:\n",
    "        results['Lights (kWh/m2)'] = pd.Series(0,index=date_index_local)\n",
    "        \n",
    "    \n",
    "    #equipment\n",
    "    if 'InteriorEquipment__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Equipment (kWh/m2)'] = idf.meters.OutputMeter.InteriorEquipment__Electricity.values(units = ('kWh'))/area\n",
    "    else:\n",
    "        results['Equipment (kWh/m2)'] = pd.Series(0,index=date_index_local)\n",
    "        \n",
    "    if 'Refrigeration__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['Equipment (kWh/m2)'] += idf.meters.OutputMeter.Refrigeration__Electricity.values(units = ('kWh'))/area\n",
    "        \n",
    "    \n",
    "    #hot water \n",
    "    if 'WaterSystems__Gas' in idf.meters.OutputMeter.__dict__:\n",
    "        results['DHW (kWh/m2)'] = idf.meters.OutputMeter.WaterSystems__Gas.values(units = ('kWh'))/area\n",
    "    else:\n",
    "        results['DHW (kWh/m2)'] = pd.Series(0,index=date_index_local)\n",
    "        \n",
    "    if 'WaterSystems__Electricity' in idf.meters.OutputMeter.__dict__:\n",
    "        results['DHW (kWh/m2)'] += idf.meters.OutputMeter.WaterSystems__Electricity.values(units = ('kWh'))/area\n",
    "\n",
    "    \n",
    "    #total EUI\n",
    "    results['EUI (kWh/m2)'] = results.apply(lambda row: \n",
    "                                              row['DHW (kWh/m2)']+\n",
    "                                              row['Equipment (kWh/m2)']+\n",
    "                                              row['Lights (kWh/m2)']+\n",
    "                                              row['Heating (kWh/m2)']+\n",
    "                                              row['Cooling (kWh/m2)'], \n",
    "                                              axis = 1)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this cell to get the weather file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weather file\n",
    "ep_weather = next(iter((Path(climate_region) / 'WeatherFile').files(\"*.epw\")), None)\n",
    "if not ep_weather:\n",
    "    raise Exception(\"No weather file found\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Variables for Scripts Below\n",
    "\n",
    "If all EnergyPlus **simulations have already been completed** for all IDF files in the climate region, `simulate = False`. Otherwise, set `simulate = True`.\n",
    "\n",
    "If you are running scripts in **testing mode** (e.g., you don't want to run through all buildings or you don't want to overwrite any results), set `testing = True` and specify which buildings you want to use in your test script. \n",
    "\n",
    "If there are **no UMI results** but still want to generate a worksheet with space for UMI results, set `compare_umi = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate=False\n",
    "\n",
    "testing = True\n",
    "all_buildings_test = ['Warehouse',\n",
    "                      'Stand-aloneRetail']\n",
    "\n",
    "compare_umi=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blank dictionary to store IDFs. Only run once for each notebook (then set `run = False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "\n",
    "if run:\n",
    "    idfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to generate an Excel spreadsheet with EnergyPlus results only (*no UMI comparison*)\n",
    "\n",
    "If an EP-Results.xlsx file already exists, every time the script is run, the results will be appended as a new sheet. If you want to start over creating an EP-Results.xlsx file, delete the existing one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1 = True\n",
    "\n",
    "if run1:\n",
    "     # create code for file\n",
    "    if testing:\n",
    "        file_code = '_test_' \n",
    "        buildings_list = all_buildings_test\n",
    "    else:\n",
    "        file_code = '_'\n",
    "        buildings_list = all_buildings\n",
    "\n",
    "\n",
    "    #check if file already exists\n",
    "    fname = Path(climate_region) / f'{climate_region}{file_code}EP-Results.xlsx'\n",
    "    \n",
    "    if fname.isfile():\n",
    "        w_a = 'a'\n",
    "    else:\n",
    "        w_a = 'w'\n",
    "\n",
    "    #excel document to save results (mode='w' for write, mode='a' for append)\n",
    "    with pd.ExcelWriter(fname, mode=w_a) as writer:\n",
    "\n",
    "        #loop through all building types\n",
    "        for bldg in buildings_list: \n",
    "\n",
    "            #empty list of results dataframes for the epoch\n",
    "            epoch_dfs = []\n",
    "\n",
    "            # loop through all epochs\n",
    "            for epoch in all_epochs:\n",
    "                ep_file = next(iter((Path(climate_region) / \"IDF\").files(f\"*{bldg}{epoch}*.idf\")), None)\n",
    "                if not ep_file:\n",
    "                    raise FileNotFoundError(f\"Cound not find file for {bldg}{epoch}\")\n",
    "\n",
    "                #read idf\n",
    "                idfs[f\"{bldg}{epoch}\"] = ar.IDF(ep_file, ep_weather, as_version = ep_version)\n",
    "\n",
    "                if simulate:\n",
    "                    #simulate idf\n",
    "                    idfs[f\"{bldg}{epoch}\"].simulate()\n",
    "\n",
    "                #get results and make dataframe for epoch + building combo\n",
    "                results = getResultsDF(idfs[f\"{bldg}{epoch}\"])\n",
    "\n",
    "                #group results by monthly and add totals row\n",
    "                monthly_results = results.groupby(results.index.month).sum()\n",
    "                monthly_results.index.map(str)\n",
    "\n",
    "                # add total row\n",
    "                monthly_w_tot = monthly_results.append(monthly_results.sum().rename('Annual'))\n",
    "\n",
    "                #concat results with umi and error dataframes\n",
    "                #results_all \n",
    "\n",
    "                #swap the order of the headers and sort\n",
    "                #results_swapped = results_all.swaplevel(axis=1).sort_index(axis=1).loc[:, (energy_header, sim_header)]\n",
    "\n",
    "                #add temporary results to list of epoch results\n",
    "                epoch_dfs.append(monthly_w_tot)\n",
    "\n",
    "            # concat all dfs\n",
    "            annual = pd.concat(epoch_dfs, keys=all_epochs, names = ['Epoch','Energy Type'], axis = 1)\n",
    "            annual.index.name = 'Month'\n",
    "\n",
    "            # get floor area\n",
    "            area_blg = idfs[f\"{bldg}{epoch}\"].net_conditioned_building_area\n",
    "            # add area to sheet name\n",
    "            Name_Area = f\"{bldg}_{round(area_blg)}m2\"\n",
    "\n",
    "            # write results of building to new sheet\n",
    "            annual.to_excel(writer, sheet_name=Name_Area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to read in EP-Results.xlsx file into a DataFrames\n",
    "\n",
    "The script reads in the Excel file and stores each building Sheet as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is B253-0D67\n",
      "\n",
      " Directory of C:\\Users\\Mariana\\Desktop\\Projects\\BuildingTechnology\\DOE_Eplus_RefBuildings\\DOE_Analysis\\5a\n",
      "\n",
      "01/06/2021  03:44 PM    <DIR>          .\n",
      "01/06/2021  03:44 PM    <DIR>          ..\n",
      "01/06/2021  03:39 PM            71,117 5a_EP-Results.xlsx\n",
      "01/06/2021  03:44 PM            11,036 5a_test_EP-Results.xlsx\n",
      "01/06/2021  11:56 AM    <DIR>          cache\n",
      "12/22/2020  05:46 PM    <DIR>          data\n",
      "12/22/2020  05:43 PM    <DIR>          IDF\n",
      "12/22/2020  05:46 PM    <DIR>          images\n",
      "12/22/2020  05:46 PM    <DIR>          logs\n",
      "01/06/2021  03:25 PM    <DIR>          UMI\n",
      "12/22/2020  05:43 PM    <DIR>          WeatherFile\n",
      "               2 File(s)         82,153 bytes\n",
      "               9 Dir(s)  79,335,895,040 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is B253-0D67\n",
      "\n",
      " Directory of C:\\Users\\Mariana\\Desktop\\Projects\\BuildingTechnology\\DOE_Eplus_RefBuildings\\DOE_Analysis\n",
      "\n",
      "01/06/2021  05:38 PM    <DIR>          .\n",
      "01/06/2021  05:38 PM    <DIR>          ..\n",
      "12/22/2020  05:42 PM             1,928 .gitignore\n",
      "12/22/2020  05:47 PM    <DIR>          .ipynb_checkpoints\n",
      "01/06/2021  03:44 PM    <DIR>          5a\n",
      "01/06/2021  05:34 PM    <DIR>          cache\n",
      "01/06/2021  05:34 PM    <DIR>          data\n",
      "01/06/2021  05:38 PM            44,756 DOE_Analysys.ipynb\n",
      "01/06/2021  05:34 PM    <DIR>          images\n",
      "01/06/2021  05:34 PM    <DIR>          logs\n",
      "12/22/2020  05:42 PM                62 README.md\n",
      "               3 File(s)         46,746 bytes\n",
      "               8 Dir(s)  79,338,045,440 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1ad72cc392a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresults_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{climate_region}/{climate_region}_EP-Results.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\EP_environment\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'xls'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'; not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[1;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_fname = f'{climate_region}/{climate_region}_EP-Results.xlsx'\n",
    "\n",
    "pd.read_excel(results_fname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to pull in UMI results and Compare with EnergyPlus Results\n",
    "\n",
    "If EnergyPlus results already exist in an EP-Results.xlsx file, this script reads those in. Otherwise, the script runs EnergyPlus simulations and creates two files: EP-Results.xlsx and ResultsComparison.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2 = False\n",
    "\n",
    "if run2:\n",
    "\n",
    "    os.chdir(climate_region)\n",
    "\n",
    "    # create blank dictionary to store IDFs\n",
    "    idfs = {}\n",
    "\n",
    "    # create code for file\n",
    "    if testing:\n",
    "        file_code = '_test_' \n",
    "        buildings_list = all_buildings_test\n",
    "    else:\n",
    "        file_code = '_'\n",
    "        buildings_list = all_buildings\n",
    "\n",
    "\n",
    "    #check if file already exists\n",
    "    fname = f'{climate_region}{file_code}EP-Results.xlsx'\n",
    "    if os.path.isfile(fname):\n",
    "        w_a = 'a'\n",
    "    else:\n",
    "        w_a = 'w'\n",
    "\n",
    "    #excel document to save results (mode='w' for write, mode='a' for append)\n",
    "    with pd.ExcelWriter(fname, mode=w_a) as writer:\n",
    "\n",
    "        #loop through all building types\n",
    "        for bldg in buildings_list: \n",
    "\n",
    "            #empty list of results dataframes for the epoch\n",
    "            epoch_dfs = []\n",
    "\n",
    "            # loop through all epochs\n",
    "            for epoch in all_epochs:\n",
    "                ep_file = next(iter(Path(\"IDF\").files(f\"*{bldg}{epoch}*.idf\")), None)\n",
    "                if not ep_file:\n",
    "                    raise FileNotFoundError(f\"Cound not find file for {bldg}{epoch}\")\n",
    "\n",
    "                #read idf\n",
    "                idfs[f\"{bldg}{epoch}\"] = ar.IDF(ep_file, ep_weather, as_version = ep_version)\n",
    "\n",
    "                if simulate:\n",
    "                    #simulate idf\n",
    "                    idfs[f\"{bldg}{epoch}\"].simulate()\n",
    "\n",
    "                #get results and make dataframe for epoch + building combo\n",
    "                results = getResultsDF(idfs[f\"{bldg}{epoch}\"])\n",
    "\n",
    "                #group results by monthly and att totals row\n",
    "                monthly_results = results.groupby(results.index.month).sum()\n",
    "                monthly_results.index.map(str)\n",
    "\n",
    "                # add total row\n",
    "                monthly_tot = monthly_results.append(monthly_results.sum().rename('Annual'))\n",
    "\n",
    "                # read in umi file\n",
    "                if compare_umi:\n",
    "                    py_umi = pd.DataFrame(0,index=date_index,columns=energy_header)  \n",
    "                    #####################################################\n",
    "                    ###### SAM TO ADD CODE HERE ######\n",
    "                    # this will need to be replaced with a function that reads \n",
    "                    # results from pyumi for each building-epoch combo\n",
    "                    #####################################################\n",
    "                else:\n",
    "                    py_umi = pd.DataFrame(0,index=date_index,columns=energy_header)  \n",
    "\n",
    "                #reformat umi results\n",
    "                umi_month = py_umi.groupby(py_umi.index.month).sum()\n",
    "                umi_month.index.map(str)\n",
    "                umi = umi_month.append(umi_month.sum().rename('Annual'))\n",
    "\n",
    "                # create error dataframe\n",
    "                error_df = (umi-monthly_tot)/monthly_tot\n",
    "\n",
    "                #concat results with umi and error dataframes\n",
    "                results_all = pd.concat([monthly_tot, umi, error_df], \n",
    "                                             keys = sim_header, \n",
    "                                             names=['Simulation Type','Energy Type'], \n",
    "                                             axis = 1)\n",
    "                #swap the order of the headers and sort\n",
    "                results_swapped = results_all.swaplevel(axis=1).sort_index(axis=1).loc[:, (energy_header, sim_header)]\n",
    "\n",
    "                # add floor area row\n",
    "                area_blg = idfs[f\"{bldg}{epoch}\"].net_conditioned_building_area\n",
    "                area_df = pd.DataFrame(area_blg,index=['Conditioned Area m2'],columns=results_swapped.columns)\n",
    "                results_with_area = pd.concat([results_swapped,area_df])\n",
    "\n",
    "                #add temporary results to list of epoch results\n",
    "                epoch_dfs.append(results_with_area)\n",
    "\n",
    "            # concat all dfs\n",
    "            annual = pd.concat(epoch_dfs, keys=all_epochs, names = ['Epoch','Energy Type','Simulation Type'], axis = 1)\n",
    "            annual.index.name = 'Month'\n",
    "\n",
    "            # get floor area\n",
    "            area_blg = idfs[f\"{bldg}{epoch}\"].net_conditioned_building_area\n",
    "            # add area to sheet name\n",
    "            Name_Area = f\"{bldg}_{round(area_blg)}m2\"\n",
    "\n",
    "            # write results of building to new sheet\n",
    "            annual.to_excel(writer, sheet_name=Name_Area)\n",
    "\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExpandObjects #0-RefBldgOutPatientPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 3.35it/s]\n",
      "EnergyPlus #0-RefBldgOutPatientPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 210it [09:27, 2.70s/it] \n",
      "ExpandObjects #0-RefBldgOutPatientPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 3.74it/s]\n",
      "EnergyPlus #0-RefBldgOutPatientPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 211it [08:19, 2.37s/it] \n",
      "ExpandObjects #0-RefBldgOutPatientNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 3.52it/s]\n",
      "EnergyPlus #0-RefBldgOutPatientNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 213it [12:40, 3.57s/it] \n",
      "ExpandObjects #0-RefBldgSmallHotelPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:01, 2.33it/s]\n",
      "EnergyPlus #0-RefBldgSmallHotelPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 179it [07:35, 2.55s/it] \n",
      "ExpandObjects #0-RefBldgSmallHotelPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 6.15it/s]\n",
      "EnergyPlus #0-RefBldgSmallHotelPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 183it [05:54, 1.94s/it] \n",
      "ExpandObjects #0-RefBldgSmallHotelNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 4.17it/s]\n",
      "EnergyPlus #0-RefBldgSmallHotelNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 182it [04:12, 1.39s/it] \n",
      "ExpandObjects #0-RefBldgLargeHotelPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 5.51it/s]\n",
      "EnergyPlus #0-RefBldgLargeHotelPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 188it [01:45, 1.78it/s] \n",
      "ExpandObjects #0-RefBldgLargeHotelPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 7.93it/s]\n",
      "EnergyPlus #0-RefBldgLargeHotelPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 186it [01:47, 1.73it/s] \n",
      "ExpandObjects #0-RefBldgLargeHotelNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 10.7it/s]\n",
      "EnergyPlus #0-RefBldgLargeHotelNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 191it [01:37, 1.96it/s] \n",
      "ExpandObjects #0-RefBldgMidriseApartmentPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 7.42it/s]\n",
      "EnergyPlus #0-RefBldgMidriseApartmentPre1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 182it [01:50, 1.65it/s] \n",
      "ExpandObjects #0-RefBldgMidriseApartmentPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 8.94it/s]\n",
      "EnergyPlus #0-RefBldgMidriseApartmentPost1980_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 182it [02:12, 1.38it/s] \n",
      "ExpandObjects #0-RefBldgMidriseApartmentNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 3.00it [00:00, 5.62it/s]\n",
      "EnergyPlus #0-RefBldgMidriseApartmentNew2004_v1.4_7.2_5A_USA_IL_CHICAGO-OHARE.idf: 182it [02:08, 1.42it/s] \n"
     ]
    }
   ],
   "source": [
    "#### OLD CODE ######\n",
    "\n",
    "run3 = False\n",
    "\n",
    "if run3:\n",
    "\n",
    "    # create blank dictionary to store IDFs\n",
    "    idfs = {}\n",
    "\n",
    "    # create code for file\n",
    "    if testing:\n",
    "        file_code = '_test_' \n",
    "        buildings_list = all_buildings_test\n",
    "    else:\n",
    "        file_code = '_'\n",
    "        buildings_list = all_buildings\n",
    "\n",
    "\n",
    "    #check if file already exists\n",
    "    fname = f'{climate_region}{file_code}ResultsComparison.xlsx'\n",
    "    if os.path.isfile(fname):\n",
    "        w_a = 'a'\n",
    "    else:\n",
    "        w_a = 'w'\n",
    "\n",
    "    #excel document to save results (mode='w' for write, mode='a' for append)\n",
    "    with pd.ExcelWriter(fname, mode=w_a) as writer:\n",
    "\n",
    "        #loop through all building types\n",
    "        for bldg in buildings_list: \n",
    "\n",
    "            #empty list of results dataframes for the epoch\n",
    "            epoch_dfs = []\n",
    "\n",
    "            # loop through all epochs\n",
    "            for epoch in all_epochs:\n",
    "                ep_file = next(iter(Path(\"IDF\").files(f\"*{bldg}{epoch}*.idf\")), None)\n",
    "                if not ep_file:\n",
    "                    raise FileNotFoundError(f\"Cound not find file for {bldg}{epoch}\")\n",
    "\n",
    "                #read idf\n",
    "                idfs[f\"{bldg}{epoch}\"] = ar.IDF(ep_file, ep_weather, as_version = ep_version)\n",
    "\n",
    "                if simulate:\n",
    "                    #simulate idf\n",
    "                    idfs[f\"{bldg}{epoch}\"].simulate()\n",
    "\n",
    "                #get results and make dataframe for epoch + building combo\n",
    "                results = getResultsDF(idfs[f\"{bldg}{epoch}\"])\n",
    "\n",
    "                #group results by monthly and att totals row\n",
    "                monthly_results = results.groupby(results.index.month).sum()\n",
    "                monthly_results.index.map(str)\n",
    "\n",
    "                # add total row\n",
    "                monthly_tot = monthly_results.append(monthly_results.sum().rename('Annual'))\n",
    "\n",
    "                # read in umi file\n",
    "                if compare_umi:\n",
    "                    py_umi = pd.DataFrame(0,index=date_index,columns=energy_header)  \n",
    "                    #####################################################\n",
    "                    ###### SAM TO ADD CODE HERE ######\n",
    "                    # this will need to be replaced with a function that reads \n",
    "                    # results from pyumi for each building-epoch combo\n",
    "                    #####################################################\n",
    "                else:\n",
    "                    py_umi = pd.DataFrame(0,index=date_index,columns=energy_header)  \n",
    "\n",
    "                #reformat umi results\n",
    "                umi_month = py_umi.groupby(py_umi.index.month).sum()\n",
    "                umi_month.index.map(str)\n",
    "                umi = umi_month.append(umi_month.sum().rename('Annual'))\n",
    "\n",
    "                # create error dataframe\n",
    "                error_df = (umi-monthly_tot)/monthly_tot\n",
    "\n",
    "                #concat results with umi and error dataframes\n",
    "                results_all = pd.concat([monthly_tot, umi, error_df], \n",
    "                                             keys = sim_header, \n",
    "                                             names=['Simulation Type','Energy Type'], \n",
    "                                             axis = 1)\n",
    "                #swap the order of the headers and sort\n",
    "                results_swapped = results_all.swaplevel(axis=1).sort_index(axis=1).loc[:, (energy_header, sim_header)]\n",
    "\n",
    "                # add floor area row\n",
    "                area_blg = idfs[f\"{bldg}{epoch}\"].net_conditioned_building_area\n",
    "                area_df = pd.DataFrame(area_blg,index=['Conditioned Area m2'],columns=results_swapped.columns)\n",
    "                results_with_area = pd.concat([results_swapped,area_df])\n",
    "\n",
    "                #add temporary results to list of epoch results\n",
    "                epoch_dfs.append(results_with_area)\n",
    "\n",
    "            # concat all dfs\n",
    "            annual = pd.concat(epoch_dfs, keys=all_epochs, names = ['Epoch','Energy Type','Simulation Type'], axis = 1)\n",
    "            annual.index.name = 'Month'\n",
    "\n",
    "            # get floor area\n",
    "            area_blg = idfs[f\"{bldg}{epoch}\"].net_conditioned_building_area\n",
    "            # add area to sheet name\n",
    "            Name_Area = f\"{bldg}_{round(area_blg)}m2\"\n",
    "\n",
    "            # write results of building to new sheet\n",
    "            annual.to_excel(writer, sheet_name=Name_Area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick umi compare (with a completed DOE results excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EP_environment",
   "language": "python",
   "name": "ep_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
